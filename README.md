# **머신러닝과 딥러닝 모델을 활용한 ELL 학습자 에세이 자동 채점 모델**
 **프로젝트 기간**: 2024.09 ~ 2024.12  
 **개인 프로젝트**  

## **1. 분석 목적**
ELL 학생들의 에세이를 자동 채점하기 위해 **머신러닝과 딥러닝 기술을 활용한 채점 모델을 구축**합니다.  
평가 기준에 기반한 **공정하고 효율적인 채점을 통해 학생들의 글쓰기 능력을 향상**시키고, 교사의 부담을 완화하는 것을 목표로 합니다.  

## **2. 분석 개요**

###  데이터 수집
- **데이터 출처**  
  - Kaggle에서 제공된 **3,911개의 ELL 학생 에세이 데이터셋 활용**  

###  데이터 전처리
- **텍스트 정제 과정**  
  - **대소문자 변환**, **특수 문자 제거**, **불용어 제거**  
  - **TF-IDF 벡터화 적용 등**  

###  분석 방법론
#### **1️ 다중출력 머신러닝 회귀 (Multi-output Regression)**
- **모델 적용**  
  - **SVR**, **랜덤 포레스트 회귀**, **XGBoost**를 사용하여 에세이 평가 점수 예측  
- **성능 평가 지표**  
  - R² 점수 (설명력)  
  - MSE (Mean Squared Error, 평균제곱오차)  

#### **2️ 딥러닝 모델**
- **RoBERTa 기반 딥러닝 모델 적용**  
  - 문맥 정보를 학습하여 예측 성능 향상  
  - **RoBERTa의 사전 학습된 토크나이저** 및 **선형 회귀 레이어 추가**하여 각 평가 기준 점수 예측    

###  Train 데이터 적합성 검증 실험
#### **실험 1: 상위권 점수 데이터 제거 실험**
- Train 데이터에서 **평균 점수 4점 이상의 고득점 데이터를 제거**하고 학습  
- 제거된 데이터를 Test 데이터로 사용하여 **예측 성능 분석**  
- 같은 과정을 **하위권 점수 데이터 제거 실험**으로도 수행  

#### **실험 2: 상위권 데이터에 오류를 추가한 민감도 실험**
- **상위권 점수 데이터를 Test 데이터로 설정**한 뒤 철자 및 문법 오류를 **단계적으로 추가하여 모델의 민감도를 평가**  
- 같은 과정을 **하위권 점수 데이터에도 동일하게 적용**  

## **3. 분석 결과**
 **모델 성능 비교**  
- **머신러닝 모델**  
  - **랜덤 포레스트 회귀 모델**이 가장 높은 설명력 (**R²: 0.887**)과  
    낮은 오차 (**MSE: 0.048**)를 기록  
- **딥러닝 모델**  
  - **RoBERTa 모델**이 문맥적 관계를 반영하여 **가장 우수한 예측 성능**을 보임  

 **결론**  
- **에세이 평가에서 문맥적 이해가 중요한 경우** → **딥러닝 모델 (RoBERTa) 사용**  
- **효율성과 계산 비용을 고려할 경우** → **랜덤 포레스트 모델 활용**  

## **4. 리뷰**
 **프로젝트 경험**  
- Train 데이터의 적합성을 검증하는 과정의 중요성을 배울 수 있어 **유의미한 경험**이었음.  
- 또한, **텍스트 데이터 전처리부터 딥러닝 모델 학습까지의 전 과정을 교수님과 직접 진행**할 수 있어 더욱 뜻깊었음.  
